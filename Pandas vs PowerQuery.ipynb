{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below we are reading in our dictionary Excel file specifying the sheet name and the columns (C:C, E:E) that we care about. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glos = pd.read_excel('CollegeScorecardDataDictionary.xlsx',sheet_name='data_dictionary',usecols='C,E', index_col = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html) for `index_col` shows that it's 0-indexed which means we're specifying the 2nd of our two columns that we explicitly read in.  Below you can see that E:E *'VARIABLE NAME'* is our index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>developer-friendly name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VARIABLE NAME</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UNITID</th>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPEID</th>\n",
       "      <td>ope8_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPEID6</th>\n",
       "      <td>ope6_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSTNM</th>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CITY</th>\n",
       "      <td>city</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              developer-friendly name\n",
       "VARIABLE NAME                        \n",
       "UNITID                             id\n",
       "OPEID                         ope8_id\n",
       "OPEID6                        ope6_id\n",
       "INSTNM                           name\n",
       "CITY                             city"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we specify the sub-string we're looking for in our column headers and convert the DataFrame to a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = 'male.completed_by.4'\n",
    "glos = glos.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cols = ['INSTNM']\n",
    "cols = default_cols + [k for k,v in glos['developer-friendly name'].items() if lf in str(v)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above we set the columns we want to load from our annual data files with a [list comprehension](http://www.secnetix.de/olli/Python/list_comprehensions.hawk). We are only pulling in institution name and male/female 4 year graduation rate. We could simply remove the '4' from `lf` and we'd have all graduation rate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FEMALE_COMP_ORIG_YR6_RT',\n",
       " 'MALE_COMP_ORIG_YR3_RT',\n",
       " 'MALE_COMP_ORIG_YR2_RT',\n",
       " 'FEMALE_COMP_ORIG_YR3_RT',\n",
       " 'FEMALE_COMP_ORIG_YR8_RT',\n",
       " 'MALE_COMP_ORIG_YR4_RT',\n",
       " 'FEMALE_COMP_ORIG_YR2_RT',\n",
       " 'MALE_COMP_ORIG_YR8_RT',\n",
       " 'FEMALE_COMP_ORIG_YR4_RT',\n",
       " 'MALE_COMP_ORIG_YR6_RT']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k,v in glos['developer-friendly name'].items() if 'male.completed_by.' in str(v)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We grab the files in our current directory and begin to iterate over them. Our `usecols` argument is only loading what we need rather than the 2000+ columns that exist. We definitely want to do this as it is faster and will not use RAM needlessly.  \n",
    "\n",
    "#### `dropna()` is operating on rows `axis=0` as opposed to columns `axis=1` and it is dropping rows where *any* data is missing. If the school provides male rate but not female, we're not keeping that school.\n",
    "\n",
    "#### `df['year'] = file[6:10]` is adding the year portion of the file name as a new column so that we can later group by each years data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [x for x in os.listdir() if x.endswith('.csv')]\n",
    "\n",
    "frames = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file,usecols=cols).dropna(axis=0,how='any')\n",
    "    df['year'] = file[6:10]\n",
    "    frames.append(df)\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you may have gathered the `glos` variable is somewhat contrived. I really only showed it here to give an example of a few of pandas useful features.\n",
    "\n",
    "#### We rename and we do it in place below. Notice we are not assigning this operation to a `df` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns=glos['developer-friendly name'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some schools did not publish this data so below we are removing schools that supressed this for either males, females, or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.values != 'PrivacySuppressed').all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we define a new column into existence by simply subtracting one column from another. We perform the operation `astype` float because they were not read in as decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta'] = df['title_iv.female.completed_by.4yrs'].astype(float) - df['title_iv.male.completed_by.4yrs'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we want to group by this new column our bands must be set. I have chosen greater than 0, less than 0, and exactly 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [(df['delta'] == 0),(df['delta'] > 0),(df['delta'] < 0)]\n",
    "choices = ['No Difference','Female Higher','Male Higher']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Again, we define a column into existence by performing an assignment by way of a [numpy.select](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.select.html) operation.  Now we need only groupby our new column and display the size of the groups!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "difference\n",
       "Female Higher    39874\n",
       "Male Higher      11661\n",
       "No Difference       36\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['difference'] = np.select(conditions, choices)\n",
    "\n",
    "df.groupby('difference').size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below we are grouping by the year then getting the average of the `delta` and multiplying by 100 to show as percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2002    1.431179\n",
       "2003    2.719079\n",
       "2004    3.487616\n",
       "2005    4.126044\n",
       "2006    4.060755\n",
       "2007    4.114775\n",
       "2008    4.464936\n",
       "2009    4.455689\n",
       "2010    4.010999\n",
       "2011    4.065882\n",
       "2012    4.286755\n",
       "2013    4.421217\n",
       "2014    4.151333\n",
       "Name: delta, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('year')['delta'].mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
